{"ast":null,"code":"import { createElementVNode as _createElementVNode, toDisplayString as _toDisplayString, createTextVNode as _createTextVNode, openBlock as _openBlock, createElementBlock as _createElementBlock } from \"vue\";\nconst _hoisted_1 = [\"disabled\"];\nconst _hoisted_2 = [\"disabled\"];\nconst _hoisted_3 = /*#__PURE__*/_createElementVNode(\"br\", null, null, -1 /* HOISTED */);\nconst _hoisted_4 = {\n  name: \"\",\n  id: \"\",\n  cols: \"30\",\n  rows: \"10\"\n};\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  return _openBlock(), _createElementBlock(\"div\", null, [_createElementVNode(\"button\", {\n    onClick: _cache[0] || (_cache[0] = (...args) => $options.startRecognition && $options.startRecognition(...args)),\n    disabled: $data.isListening\n  }, \" Start \", 8 /* PROPS */, _hoisted_1), _createElementVNode(\"button\", {\n    onClick: _cache[1] || (_cache[1] = (...args) => $options.stopRecognition && $options.stopRecognition(...args)),\n    disabled: !$data.isListening\n  }, \" Stop \", 8 /* PROPS */, _hoisted_2), _createTextVNode(), _hoisted_3, _createElementVNode(\"textarea\", _hoisted_4, _toDisplayString($data.transcript), 1 /* TEXT */)]);\n}","map":{"version":3,"names":["_createElementVNode","name","id","cols","rows","_createElementBlock","onClick","_cache","args","$options","startRecognition","disabled","$data","isListening","_hoisted_1","stopRecognition","_hoisted_2","_hoisted_3","_hoisted_4","_toDisplayString","transcript"],"sources":["D:\\kuliah\\Sem 4\\Tekmul\\vue-router\\client\\src\\views\\main.vue"],"sourcesContent":["<template>\r\n  <div>\r\n    <button @click=\"startRecognition\" :disabled=\"isListening\">\r\n      Start\r\n    </button>\r\n    <button @click=\"stopRecognition\" :disabled=\"!isListening\">\r\n      Stop\r\n    </button> <br>\r\n    <textarea name=\"\" id=\"\" cols=\"30\" rows=\"10\">{{ transcript }}</textarea>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nexport default {\r\n  data() {\r\n    return {\r\n      isListening: false,\r\n      transcript: \"\",\r\n      recognition: null,\r\n    };\r\n  },\r\n  mounted() {\r\n    const speechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    this.recognition = new speechRecognition();\r\n    this.recognition.lang = \"id-ID\";\r\n    this.recognition.interimResults = true;\r\n    this.recognition.maxAlternatives = 1;\r\n\r\n    this.recognition.onstart = () => {\r\n      console.log(\"Speech recognition service has started\");\r\n      this.isListening = true;\r\n    };\r\n\r\n    this.recognition.onresult = (event) => {\r\n      const resultIndex = event.resultIndex;\r\n      this.transcript = event.results[resultIndex][0].transcript;\r\n      console.log(this.transcript);\r\n    };\r\n\r\n    this.recognition.onend = () => {\r\n      console.log(\"Speech recognition service disconnected\");\r\n      this.isListening = false;\r\n    };\r\n\r\n    this.recognition.onerror = (event) => {\r\n      console.log(\"Error occurred in recognition: \" + event.error);\r\n      this.isListening = false;\r\n    };\r\n  },\r\n  methods: {\r\n    startRecognition() {\r\n      this.recognition.start();\r\n    },\r\n    stopRecognition() {\r\n      this.recognition.stop();\r\n    },\r\n  },\r\n};\r\n</script>\r\n"],"mappings":";;;gCAOcA,mBAAA,CAAI;;EACJC,IAAI,EAAC,EAAE;EAACC,EAAE,EAAC,EAAE;EAACC,IAAI,EAAC,IAAI;EAACC,IAAI,EAAC;;;uBAPzCC,mBAAA,CAQM,cAPJL,mBAAA,CAES;IAFAM,OAAK,EAAAC,MAAA,QAAAA,MAAA,UAAAC,IAAA,KAAEC,QAAA,CAAAC,gBAAA,IAAAD,QAAA,CAAAC,gBAAA,IAAAF,IAAA,CAAgB;IAAGG,QAAQ,EAAEC,KAAA,CAAAC;KAAa,SAE1D,iBAAAC,UAAA,GACAd,mBAAA,CAES;IAFAM,OAAK,EAAAC,MAAA,QAAAA,MAAA,UAAAC,IAAA,KAAEC,QAAA,CAAAM,eAAA,IAAAN,QAAA,CAAAM,eAAA,IAAAP,IAAA,CAAe;IAAGG,QAAQ,GAAGC,KAAA,CAAAC;KAAa,QAE1D,iBAAAG,UAAA,G,oBAAUC,UAAI,EACdjB,mBAAA,CAAuE,YAAvEkB,UAAuE,EAAAC,gBAAA,CAAxBP,KAAA,CAAAQ,UAAU,iB"},"metadata":{},"sourceType":"module","externalDependencies":[]}